{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import tools\n",
    "import numpy as np\n",
    "# from sklearn import svm\n",
    "# import sklearn.model_selection as sm\n",
    "from settings import *\n",
    "from unionfind import UnionFind\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本代码使用python3(版本需>=3.6), 需要使用的包在`requirements.txt`.\n",
    "\n",
    "首先需要创建一个`data`目录,并将数据都放到里面, 数据在[这里可以下载到](https://biendata.com/competition/scholar2018/data/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局度量学习 Global metric learning  \n",
    "\n",
    "请直接执行`python global_embedding.py`来生成全局论文向量表示.  \n",
    "\n",
    "# 建立论文图  prepare local data  \n",
    "请到`local`目录下执行`prepare_localdata.py`文件:    \n",
    "\n",
    "```sh\n",
    "cd local \n",
    "python prepare_localdata.py \n",
    "\n",
    "```  \n",
    "\n",
    "# 利用强规则生成Pair-wise constraint  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rules.pos\n",
    "rules.pos.generate_positive_pair() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 并查集算法 Union-Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ass_train = json.load(open(assignments_train_path))\n",
    "ass_val = json.load(open(VAL_NAME2PUB)\n",
    "testname2ids = json.load(open('./data/await_test.json'))\n",
    "valname2ids = ass_val\n",
    "trainname2ids = defaultdict(list)\n",
    "for name, pubs in ass_train.items():\n",
    "    trainname2ids[name] = [i for pub in pubs for i in pub]\n",
    "\n",
    "pos_pair = json.load(open(pos_pair_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in pos_pair.keys():\n",
    "    file_path = './output/graph-%s/%s_pubs_network.txt'%(IDF_THRESHOLD, name)\n",
    "    for line in open(file_path):\n",
    "        a, b = line.strip().split()\n",
    "        pos_pair[name].append([a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = {}\n",
    "for name, ids in trainname2ids.items():\n",
    "    uf = UnionFind(ids)\n",
    "    for pair in pos_pair[name]:\n",
    "        uf.union(*pair)\n",
    "    train_gen[name] = [list(i) for i in uf.components()]\n",
    "metric = []\n",
    "for k, v in ass_train.items():\n",
    "    ids, labs = tools.assign2label(v)\n",
    "    _, pre_labs = tools.assign2label(train_gen[k])\n",
    "\n",
    "    f1 = tools.pairwise_precision_recall_f1(pre_labs, labs)\n",
    "    \n",
    "    print(k,len(pos_pair[k]), f1, len(ass_train[k]), len(train_gen[k]))\n",
    "    metric.append(f1[-1])\n",
    "print(np.mean(metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ke_xu 5876 (0.41746817538896747, 0.18163076923076923, 0.2531303602058319) 14 137\n",
      "jing_wu 5548 (0.5370762711864406, 0.3998422712933754, 0.4584086799276672) 34 87\n",
      "d_li 10131 (0.4781599781599782, 0.5782436447672499, 0.5234608487746564) 10 41\n",
      "liang_li 14015 (0.444317923024368, 0.39873288371142446, 0.42029297716501507) 21 78\n",
      "dan_wang 8423 (0.3782051282051282, 0.5115606936416185, 0.4348894348894349) 24 77\n",
      "juan_du 4382 (0.587012987012987, 0.2100371747211896, 0.30937713894592744) 20 76\n",
      "bo_xu 16414 (0.5038889099669916, 0.5068503606457276, 0.5053652968036529) 16 111\n",
      "l_sun 22219 (0.5939342881213142, 0.7777641578818337, 0.6735311289209701) 19 33\n",
      "long_wang 10327 (0.48562680115273776, 0.6465397343053091, 0.5546481249099998) 18 53\n",
      "bing_chen 9341 (0.5120850789558492, 0.46434833430742256, 0.48704980842911877) 50 140\n",
      "c_c_lin 1601 (0.7175989085948158, 0.5723612622415669, 0.6368038740920098) 9 31\n",
      "liang_zhou 3336 (0.5474613686534217, 0.3873486919172198, 0.4536931168534187) 15 49\n",
      "jie_yang 15057 (0.4306049822064057, 0.27976878612716766, 0.33917309039943944) 21 64\n",
      "juan_zhang 5194 (0.400300978179082, 0.4907749077490775, 0.4409448818897637) 17 38\n",
      "lei_zhao 20820 (0.48356360171510243, 0.3277365192121408, 0.39068514241724406) 20 75\n",
      "h_y_wang 1217 (0.8089171974522293, 0.5515743756786102, 0.6559070367979342) 18 42\n",
      "hong_yan_wang 1171 (0.6790123456790124, 0.5641025641025641, 0.6162464985994397) 18 28\n",
      "juan_liu 5298 (0.5486827033218786, 0.562206572769953, 0.5553623188405797) 12 32\n",
      "jin_liu 3931 (1.0, 0.31731543624161074, 0.48176074994905244) 16 87\n",
      "huan_liu 2688 (0.4646153846153846, 0.4582701062215478, 0.4614209320091673) 20 39\n",
      "jian_wu 16598 (0.4448806800723772, 0.4974138753697872, 0.46968290726907375) 16 96\n",
      "ji_zhang 4436 (0.5513227513227513, 0.4938388625592417, 0.5209999999999999) 21 61\n",
      "jian_huang 6793 (0.4694467382328654, 0.3040106951871658, 0.36903602726387535) 18 52\n",
      "d_wang 261178 (0.9570242953792215, 0.9605850386268454, 0.9588013610918005) 6 13\n",
      "j_jiang 1438 (0.8172690763052208, 0.7722960151802657, 0.7941463414634146) 16 25\n",
      "fei_liu 21806 (0.25136693086932566, 0.7702948434861671, 0.3790425667902339) 12 75\n",
      "liping_liu 3429 (0.20105820105820105, 0.18536585365853658, 0.19289340101522842) 11 18\n",
      "j_ma 1913 (0.6391982182628062, 0.7103960396039604, 0.6729191090269636) 17 33\n",
      "chao_zhang 10157 (0.6352833638025595, 0.19588500563697858, 0.2994398965962947) 21 138\n",
      "guang_yang 5561 (0.8160919540229885, 0.1240174672489083, 0.21531463229719486) 19 104\n",
      "li_li_wang 2121 (0.9052287581699346, 0.6690821256038647, 0.7694444444444444) 12 30\n",
      "juan_chen 4606 (0.5555555555555556, 0.28532608695652173, 0.3770197486535009) 16 55\n",
      "chun_li 3943 (0.8614008941877794, 0.10010391409767926, 0.17936384794414273) 19 139\n",
      "li_gao 3185 (0.7649006622516556, 0.4, 0.525298465036953) 15 46\n",
      "hong_yang 8521 (0.4440629470672389, 0.5610314495722376, 0.4957410562180579) 17 56\n",
      "j_yu 584726 (0.0, 0.0, 0.0) 0 0\n",
      "chun_wang 6696 (0.51711943417457, 0.5007783312577833, 0.5088177145116647) 13 38\n",
      "d_zhang 239849 (0.2026266416510319, 0.16916115558649494, 0.18438774542350375) 16 41\n",
      "j_huang 9472 (0.7807874015748032, 0.42045454545454547, 0.5465770036379671) 10 23\n",
      "fang_chen 6060 (0.4581523884721674, 0.41639756010046647, 0.4362781954887218) 18 98\n",
      "j_y_wang 1532 (0.2878625134264232, 0.2068699343882671, 0.24073658207949697) 13 53\n",
      "g_li 52378 (0.7042765802672384, 0.6730452599612162, 0.6883068288119738) 9 23\n",
      "lin_ma 6518 (0.6318950529476846, 0.6047496596581455, 0.6180244241768434) 19 65\n",
      "ke_li 5120 (0.7, 0.33363309352517984, 0.45188794153471373) 16 60\n",
      "jie_xu 8403 (0.41388518024032045, 0.41807147673634526, 0.41596779604159684) 22 50\n",
      "kun_liu 6232 (0.2931596091205212, 0.31269160024524834, 0.3026107594936709) 13 41\n",
      "li_zhou 12457 (0.6618075801749271, 0.4370427416249519, 0.5264378478664192) 13 44\n",
      "lin_xu 9649 (0.3141528925619835, 0.22355362787620378, 0.2612206330799296) 11 66\n",
      "jing_zhou 5830 (0.4281837160751566, 0.5605356654823722, 0.4855012427506214) 34 90\n",
      "hua_li 11269 (1.0, 0.48307860262008734, 0.6514538093485462) 22 91\n",
      "0.4762824010020517\n"
     ]
    }
   ],
   "source": [
    "val = {}\n",
    "from scipy.special import comb\n",
    "ass_val = json.load(open(assignments_val_path))\n",
    "valname2ids = {k: [j for i in v for j in i] for k, v in ass_val.items()}\n",
    "for name, ids in valname2ids.items():\n",
    "    if len(ids) == 0:\n",
    "        val[name] = []\n",
    "        continue\n",
    "    uf = UnionFind(ids)\n",
    "    for pair in pos_pair[name]:\n",
    "        if (pair[0] in ids) and (pair[1] in ids):\n",
    "            uf.union(*pair)\n",
    "#     print('a')\n",
    "    val[name] = [list(i) for i in uf.components()]\n",
    "json.dump(val, open('res_union_find_val.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs_ori = json.load(open('./data/pubs_validate.json'))\n",
    "pubs_val = {}\n",
    "c = []\n",
    "for k, clus in ass_val.items():\n",
    "    pubs_val[k] = []\n",
    "    eids = set([j for i in clus for j in i])\n",
    "    c.extend([len(i) for i in clus])\n",
    "    for pub in pubs_ori[k]:\n",
    "        if pub['id'] in eids:\n",
    "            pubs_val[k].append(pub)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成测试集答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {}\n",
    "\n",
    "for name, ids in testname2ids.items():\n",
    "    \n",
    "    uf = UnionFind(ids)\n",
    "    for pair in pos_pair[name]:\n",
    "        uf.union(*pair)\n",
    "    test[name] = [list(i) for i in uf.components()]\n",
    "\n",
    "json.dump(test, open('res_union_find_test.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类  \n",
    "\n",
    "另一种解法是聚类, 这里我们以半监督聚类演示一下使用方法. 半监督聚类和聚类的调用入口均在`opendac.py`中.  \n",
    "\n",
    "在使用聚类算法前, 需要先生成精调后的paper的向量表征, 即需要:   \n",
    "\n",
    "```sh\n",
    "cd local/gae\n",
    "python train.py \n",
    "```    \n",
    "\n",
    "## Semi-supervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 15  \n",
    "\n",
    "#Generate train\n",
    "pubs_train = json.load(open(pubs_train_path))\n",
    "local_output = pkl.load(open(local_output_path,'rb'))                                                                                                                           \n",
    "p = mkl.Pool(CPU_COUNT)\n",
    "length = len(pubs_train)\n",
    "res = p.starmap(clustering_with_const,  zip( pubs_train.keys(), ['PCKMeans']*length, [cluster_num]*length) ) \n",
    "J = dict(zip(pubs_train.keys(), res))\n",
    "json.dump(J, open('assignment_train_result_for_val_PCK.json', 'w'))  \n",
    "\n",
    "\n",
    "\n",
    "#Generate validate\n",
    "pubs_train = json.load(open(pubs_validate_path))\n",
    "local_output = pkl.load(open(local_output_path,'rb'))                                                                                                                                                                         \n",
    "p = mkl.Pool(CPU_COUNT)                                \n",
    "length = len(pubs_validate)\n",
    "res = p.starmap(clustering_with_const,  zip( pubs_validate.keys(), ['PCKMeans']*length, [cluster_num]*length) ) \n",
    "J = dict(zip(pubs_validate.keys(), res))                                                                                                                                                                                      \n",
    "json.dump(J, open('assignment_validate_result_PCK.json', 'w'))      \n",
    "\n",
    "\n",
    "#Generate test\n",
    "pubs_test = json.load(open(TEST_PATH))\n",
    "local_output = pkl.load(open(local_output_path,'rb'))                                                                                                                           \n",
    "p = mkl.Pool(CPU_COUNT)\n",
    "length = len(pubs_test)\n",
    "res = p.starmap(clustering_with_const,  zip( pubs_test.keys(), ['PCKMeans']*length, [cluster_num]*length) ) \n",
    "J = dict(zip(pubs_test.keys(), res))\n",
    "json.dump(J, open('assignment_test_PC_2.json', 'w'))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
